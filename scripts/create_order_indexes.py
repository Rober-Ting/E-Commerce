"""
è®¢å•é›†åˆç´¢å¼•åˆ›å»ºè„šæœ¬

æ­¤è„šæœ¬ç”¨äºä¸º MongoDB çš„ orders é›†åˆåˆ›å»ºå¿…è¦çš„ç´¢å¼•ï¼Œä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ã€‚

ç´¢å¼•åˆ—è¡¨ï¼š
1. order_number (å”¯ä¸€ç´¢å¼•) - è®¢å•ç¼–å·
2. user_id - ç”¨æˆ·ID
3. status - è®¢å•çŠ¶æ€
4. payment_status - æ”¯ä»˜çŠ¶æ€
5. created_at - åˆ›å»ºæ—¶é—´
6. updated_at - æ›´æ–°æ—¶é—´
7. paid_at - æ”¯ä»˜æ—¶é—´
8. {user_id, created_at} - å¤åˆç´¢å¼•ï¼ˆç”¨æˆ·è®¢å•åˆ—è¡¨æŸ¥è¯¢ï¼‰
9. {status, created_at} - å¤åˆç´¢å¼•ï¼ˆæŒ‰çŠ¶æ€ç­›é€‰è®¢å•ï¼‰
10. {user_id, status} - å¤åˆç´¢å¼•ï¼ˆç”¨æˆ·ç‰¹å®šçŠ¶æ€è®¢å•ï¼‰
11. is_deleted - ç¨€ç–ç´¢å¼•ï¼ˆè½¯åˆ é™¤ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/create_order_indexes.py create       # åˆ›å»ºæ‰€æœ‰ç´¢å¼•
    python scripts/create_order_indexes.py drop --confirm # åˆ é™¤æ‰€æœ‰ç´¢å¼•
    python scripts/create_order_indexes.py stats        # æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import ASCENDING, DESCENDING
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OrderIndexManager:
    """è®¢å•ç´¢å¼•ç®¡ç†å™¨"""

    def __init__(self, mongodb_url: str = "mongodb://localhost:27017", db_name: str = "ecommerce_db"):
        """
        åˆå§‹åŒ–ç´¢å¼•ç®¡ç†å™¨

        Args:
            mongodb_url: MongoDB è¿æ¥URL
            db_name: æ•°æ®åº“åç§°
        """
        self.mongodb_url = mongodb_url
        self.db_name = db_name
        self.client = None
        self.db = None
        self.collection = None

    async def connect(self):
        """è¿æ¥åˆ° MongoDB"""
        logger.info(f"æ­£åœ¨è¿æ¥åˆ° MongoDB: {self.mongodb_url}")
        self.client = AsyncIOMotorClient(self.mongodb_url)
        self.db = self.client[self.db_name]
        self.collection = self.db["orders"]
        
        # æµ‹è¯•è¿æ¥
        await self.client.admin.command('ping')
        logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.db_name}")

    async def close(self):
        """å…³é—­ MongoDB è¿æ¥"""
        if self.client:
            self.client.close()
            logger.info("å·²å…³é—­æ•°æ®åº“è¿æ¥")

    async def create_indexes(self):
        """åˆ›å»ºæ‰€æœ‰ç´¢å¼•"""
        logger.info("=" * 80)
        logger.info("å¼€å§‹åˆ›å»ºè®¢å•é›†åˆç´¢å¼•")
        logger.info("=" * 80)

        indexes_to_create = [
            # 1. è®¢å•ç¼–å·å”¯ä¸€ç´¢å¼•
            {
                "name": "order_number_unique",
                "keys": [("order_number", ASCENDING)],
                "unique": True,
                "description": "è®¢å•ç¼–å·å”¯ä¸€ç´¢å¼•"
            },
            # 2. ç”¨æˆ·IDç´¢å¼•
            {
                "name": "user_id_index",
                "keys": [("user_id", ASCENDING)],
                "description": "ç”¨æˆ·IDç´¢å¼•ï¼ˆç”¨äºæŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰è®¢å•ï¼‰"
            },
            # 3. è®¢å•çŠ¶æ€ç´¢å¼•
            {
                "name": "status_index",
                "keys": [("status", ASCENDING)],
                "description": "è®¢å•çŠ¶æ€ç´¢å¼•ï¼ˆç”¨äºæŒ‰çŠ¶æ€ç­›é€‰è®¢å•ï¼‰"
            },
            # 4. æ”¯ä»˜çŠ¶æ€ç´¢å¼•
            {
                "name": "payment_status_index",
                "keys": [("payment_status", ASCENDING)],
                "description": "æ”¯ä»˜çŠ¶æ€ç´¢å¼•ï¼ˆç”¨äºæŒ‰æ”¯ä»˜çŠ¶æ€ç­›é€‰ï¼‰"
            },
            # 5. åˆ›å»ºæ—¶é—´ç´¢å¼•ï¼ˆé™åºï¼Œæœ€æ–°è®¢å•ä¼˜å…ˆï¼‰
            {
                "name": "created_at_index",
                "keys": [("created_at", DESCENDING)],
                "description": "åˆ›å»ºæ—¶é—´ç´¢å¼•ï¼ˆç”¨äºæŒ‰æ—¶é—´æ’åºï¼‰"
            },
            # 6. æ›´æ–°æ—¶é—´ç´¢å¼•
            {
                "name": "updated_at_index",
                "keys": [("updated_at", DESCENDING)],
                "description": "æ›´æ–°æ—¶é—´ç´¢å¼•"
            },
            # 7. æ”¯ä»˜æ—¶é—´ç´¢å¼•ï¼ˆç¨€ç–ç´¢å¼•ï¼Œå› ä¸ºä¸æ˜¯æ‰€æœ‰è®¢å•éƒ½å·²æ”¯ä»˜ï¼‰
            {
                "name": "paid_at_index",
                "keys": [("paid_at", DESCENDING)],
                "sparse": True,
                "description": "æ”¯ä»˜æ—¶é—´ç´¢å¼•ï¼ˆç¨€ç–ç´¢å¼•ï¼‰"
            },
            # 8. ç”¨æˆ·ID + åˆ›å»ºæ—¶é—´å¤åˆç´¢å¼•
            {
                "name": "user_created_compound",
                "keys": [("user_id", ASCENDING), ("created_at", DESCENDING)],
                "description": "ç”¨æˆ·ID + åˆ›å»ºæ—¶é—´å¤åˆç´¢å¼•ï¼ˆä¼˜åŒ–ç”¨æˆ·è®¢å•åˆ—è¡¨æŸ¥è¯¢ï¼‰"
            },
            # 9. çŠ¶æ€ + åˆ›å»ºæ—¶é—´å¤åˆç´¢å¼•
            {
                "name": "status_created_compound",
                "keys": [("status", ASCENDING), ("created_at", DESCENDING)],
                "description": "çŠ¶æ€ + åˆ›å»ºæ—¶é—´å¤åˆç´¢å¼•ï¼ˆä¼˜åŒ–æŒ‰çŠ¶æ€ç­›é€‰æŸ¥è¯¢ï¼‰"
            },
            # 10. ç”¨æˆ·ID + çŠ¶æ€å¤åˆç´¢å¼•
            {
                "name": "user_status_compound",
                "keys": [("user_id", ASCENDING), ("status", ASCENDING)],
                "description": "ç”¨æˆ·ID + çŠ¶æ€å¤åˆç´¢å¼•ï¼ˆæŸ¥è¯¢ç”¨æˆ·ç‰¹å®šçŠ¶æ€çš„è®¢å•ï¼‰"
            },
            # 11. è½¯åˆ é™¤æ ‡è®°ç´¢å¼•ï¼ˆç¨€ç–ç´¢å¼•ï¼‰
            {
                "name": "is_deleted_index",
                "keys": [("is_deleted", ASCENDING)],
                "sparse": True,
                "description": "è½¯åˆ é™¤æ ‡è®°ç´¢å¼•ï¼ˆç¨€ç–ç´¢å¼•ï¼Œåªç´¢å¼•å·²åˆ é™¤çš„æ–‡æ¡£ï¼‰"
            },
            # 12. è®¢å•é‡‘é¢ç´¢å¼•ï¼ˆç”¨äºé‡‘é¢èŒƒå›´æŸ¥è¯¢ï¼‰
            {
                "name": "total_amount_index",
                "keys": [("total_amount", DESCENDING)],
                "description": "è®¢å•æ€»é‡‘é¢ç´¢å¼•ï¼ˆç”¨äºæŒ‰é‡‘é¢æ’åºå’Œç­›é€‰ï¼‰"
            },
        ]

        created_count = 0
        skipped_count = 0
        failed_count = 0

        for idx, index_spec in enumerate(indexes_to_create, 1):
            try:
                logger.info(f"\n[{idx}/{len(indexes_to_create)}] æ­£åœ¨åˆ›å»ºç´¢å¼•: {index_spec['name']}")
                logger.info(f"  æè¿°: {index_spec['description']}")
                logger.info(f"  å­—æ®µ: {index_spec['keys']}")

                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
                existing_indexes = await self.collection.index_information()
                if index_spec['name'] in existing_indexes:
                    logger.info(f"  âš ï¸  ç´¢å¼•å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    skipped_count += 1
                    continue

                # å‡†å¤‡ç´¢å¼•é€‰é¡¹
                index_options = {
                    "name": index_spec["name"]
                }

                if index_spec.get("unique"):
                    index_options["unique"] = True
                if index_spec.get("sparse"):
                    index_options["sparse"] = True

                # åˆ›å»ºç´¢å¼•
                await self.collection.create_index(
                    index_spec["keys"],
                    **index_options
                )

                logger.info(f"  âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ")
                created_count += 1

            except Exception as e:
                logger.error(f"  âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {str(e)}")
                failed_count += 1

        # æ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("ç´¢å¼•åˆ›å»ºå®Œæˆ")
        logger.info("=" * 80)
        logger.info(f"âœ… æˆåŠŸåˆ›å»º: {created_count} ä¸ª")
        logger.info(f"âš ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {skipped_count} ä¸ª")
        logger.info(f"âŒ å¤±è´¥: {failed_count} ä¸ª")
        logger.info(f"ğŸ“Š æ€»è®¡: {len(indexes_to_create)} ä¸ªç´¢å¼•")
        logger.info("=" * 80)

        return created_count, skipped_count, failed_count

    async def drop_indexes(self, confirm: bool = False):
        """
        åˆ é™¤æ‰€æœ‰ç´¢å¼•ï¼ˆä¿ç•™ _id ç´¢å¼•ï¼‰

        Args:
            confirm: æ˜¯å¦ç¡®è®¤åˆ é™¤
        """
        if not confirm:
            logger.warning("âš ï¸  åˆ é™¤ç´¢å¼•éœ€è¦ç¡®è®¤ï¼Œè¯·ä½¿ç”¨ --confirm å‚æ•°")
            return

        logger.info("=" * 80)
        logger.info("å¼€å§‹åˆ é™¤è®¢å•é›†åˆç´¢å¼•")
        logger.info("=" * 80)

        try:
            # è·å–æ‰€æœ‰ç´¢å¼•
            indexes = await self.collection.index_information()
            index_names = [name for name in indexes.keys() if name != "_id_"]

            logger.info(f"æ‰¾åˆ° {len(index_names)} ä¸ªè‡ªå®šä¹‰ç´¢å¼•")

            if not index_names:
                logger.info("æ²¡æœ‰éœ€è¦åˆ é™¤çš„ç´¢å¼•")
                return

            # é€ä¸ªåˆ é™¤
            for idx, index_name in enumerate(index_names, 1):
                logger.info(f"[{idx}/{len(index_names)}] æ­£åœ¨åˆ é™¤ç´¢å¼•: {index_name}")
                await self.collection.drop_index(index_name)
                logger.info(f"  âœ… åˆ é™¤æˆåŠŸ")

            logger.info("\n" + "=" * 80)
            logger.info(f"âœ… æˆåŠŸåˆ é™¤ {len(index_names)} ä¸ªç´¢å¼•")
            logger.info("=" * 80)

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ç´¢å¼•å¤±è´¥: {str(e)}")

    async def show_index_stats(self):
        """æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=" * 80)
        logger.info("è®¢å•é›†åˆç´¢å¼•ç»Ÿè®¡")
        logger.info("=" * 80)

        try:
            # è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
            stats = await self.db.command("collStats", "orders")
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            indexes = await self.collection.index_information()

            # åŸºæœ¬ç»Ÿè®¡
            logger.info("\nğŸ“Š é›†åˆç»Ÿè®¡:")
            logger.info(f"  â€¢ æ–‡æ¡£æ•°é‡: {stats.get('count', 0):,}")
            logger.info(f"  â€¢ å­˜å‚¨å¤§å°: {stats.get('size', 0) / 1024 / 1024:.2f} MB")
            logger.info(f"  â€¢ ç´¢å¼•æ•°é‡: {len(indexes)}")
            logger.info(f"  â€¢ ç´¢å¼•å¤§å°: {stats.get('totalIndexSize', 0) / 1024 / 1024:.2f} MB")

            # è¯¦ç»†ç´¢å¼•ä¿¡æ¯
            logger.info("\nğŸ“‘ ç´¢å¼•åˆ—è¡¨:")
            for idx, (name, info) in enumerate(indexes.items(), 1):
                logger.info(f"\n  {idx}. {name}")
                logger.info(f"     é”®: {info.get('key', {})}")
                if info.get('unique'):
                    logger.info("     ç±»å‹: å”¯ä¸€ç´¢å¼•")
                if info.get('sparse'):
                    logger.info("     ç±»å‹: ç¨€ç–ç´¢å¼•")

            logger.info("\n" + "=" * 80)

        except Exception as e:
            logger.error(f"âŒ è·å–ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse

    parser = argparse.ArgumentParser(description="è®¢å•é›†åˆç´¢å¼•ç®¡ç†å·¥å…·")
    parser.add_argument(
        "action",
        choices=["create", "drop", "stats"],
        help="æ“ä½œç±»å‹: create=åˆ›å»ºç´¢å¼•, drop=åˆ é™¤ç´¢å¼•, stats=æŸ¥çœ‹ç»Ÿè®¡"
    )
    parser.add_argument(
        "--confirm",
        action="store_true",
        help="ç¡®è®¤åˆ é™¤ç´¢å¼•ï¼ˆç”¨äº drop æ“ä½œï¼‰"
    )
    parser.add_argument(
        "--db-url",
        default="mongodb://localhost:27017",
        help="MongoDB è¿æ¥URLï¼ˆé»˜è®¤: mongodb://localhost:27017ï¼‰"
    )
    parser.add_argument(
        "--db-name",
        default="ecommerce_db",
        help="æ•°æ®åº“åç§°ï¼ˆé»˜è®¤: ecommerce_dbï¼‰"
    )

    args = parser.parse_args()

    # åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
    manager = OrderIndexManager(mongodb_url=args.db_url, db_name=args.db_name)

    try:
        # è¿æ¥æ•°æ®åº“
        await manager.connect()

        # æ‰§è¡Œæ“ä½œ
        if args.action == "create":
            await manager.create_indexes()
        elif args.action == "drop":
            await manager.drop_indexes(confirm=args.confirm)
        elif args.action == "stats":
            await manager.show_index_stats()

    except Exception as e:
        logger.error(f"âŒ æ“ä½œå¤±è´¥: {str(e)}")
        sys.exit(1)
    finally:
        await manager.close()


if __name__ == "__main__":
    asyncio.run(main())

